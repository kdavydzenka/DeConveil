{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11226147-2e0d-4ccd-82b0-48ee94a10607",
   "metadata": {},
   "source": [
    "# Copy-Number-aware Differential Gene Expression\n",
    "\n",
    "## Pydeseq2CN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab891044-1489-496f-9b4a-cf366fa86bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import warnings\n",
    "from math import floor\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from typing import Literal\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a11a7e3-a529-476c-b3f9-7e2006954d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad  # type: ignore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm  # type: ignore\n",
    "from joblib import Parallel  # type: ignore\n",
    "from joblib import delayed\n",
    "from joblib import parallel_backend\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gammaln \n",
    "from scipy.special import polygamma  # type: ignore\n",
    "from scipy.stats import f  # type: ignore\n",
    "from scipy.stats import trim_mean  # type: ignore\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tools.sm_exceptions import DomainWarning  # type: ignore\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4528e647-27e9-4539-a874-30d26b3cb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydeseq2\n",
    "from pydeseq2.preprocessing import deseq2_norm\n",
    "from pydeseq2.utils import build_design_matrix\n",
    "from pydeseq2.utils import dispersion_trend\n",
    "from pydeseq2.utils import fit_alpha_mle\n",
    "from pydeseq2.utils import fit_lin_mu\n",
    "from pydeseq2.utils import fit_moments_dispersions\n",
    "from pydeseq2.utils import fit_rough_dispersions\n",
    "from pydeseq2.utils import irls_solver\n",
    "from pydeseq2.utils import get_num_processes\n",
    "from pydeseq2.utils import make_scatter\n",
    "from pydeseq2.utils import mean_absolute_deviation\n",
    "from pydeseq2.utils import nb_nll\n",
    "from pydeseq2.utils import replace_underscores\n",
    "from pydeseq2.utils import robust_method_of_moments_disp\n",
    "from pydeseq2.utils import test_valid_counts\n",
    "from pydeseq2.utils import trimmed_mean\n",
    "\n",
    "from pydeseq2.grid_search import grid_fit_alpha\n",
    "from pydeseq2.grid_search import grid_fit_beta\n",
    "\n",
    "from pydeseq2.ds import DeseqStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4aa206e1-2176-4d17-a184-259c1cc54521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore DomainWarning raised by statsmodels when fitting a Gamma GLM with identity link.\n",
    "warnings.simplefilter(\"ignore\", DomainWarning)\n",
    "# Ignore AnnData's FutureWarning about implicit data conversion.\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45bf0b-346f-4105-b660-c75965557b79",
   "metadata": {},
   "source": [
    "### Model fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b66f720c-3b41-4e88-a886-3ffc2cf5357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeseqDataSet(ad.AnnData):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        adata: Optional[ad.AnnData] = None,\n",
    "        counts: Optional[pd.DataFrame] = None,\n",
    "        metadata: Optional[pd.DataFrame] = None,\n",
    "        design_factors: Union[str, List[str]] = \"condition\",\n",
    "        continuous_factors: Optional[List[str]] = None,\n",
    "        ref_level: Optional[List[str]] = None,\n",
    "        min_mu: float = 0.5,\n",
    "        min_disp: float = 1e-8,\n",
    "        max_disp: float = 10.0,\n",
    "        refit_cooks: bool = True,\n",
    "        min_replicates: int = 7,\n",
    "        beta_tol: float = 1e-8,\n",
    "        n_cpus: Optional[int] = None,\n",
    "        batch_size: int = 128,\n",
    "        joblib_verbosity: int = 0,\n",
    "        quiet: bool = False,\n",
    "    ) -> None:\n",
    "        # Initialize the AnnData part\n",
    "        if adata is not None:\n",
    "            if counts is not None:\n",
    "                warnings.warn(\n",
    "                    \"adata was provided; ignoring counts.\", UserWarning, stacklevel=2\n",
    "                )\n",
    "            if metadata is not None:\n",
    "                warnings.warn(\n",
    "                    \"adata was provided; ignoring metadata.\", UserWarning, stacklevel=2\n",
    "                )\n",
    "            # Test counts before going further\n",
    "            #test_valid_counts(adata.X)\n",
    "            # Copy fields from original AnnData\n",
    "            self.__dict__.update(adata.__dict__)\n",
    "        \n",
    "        elif counts is not None and metadata is not None:\n",
    "            # Test counts before going further\n",
    "            #test_valid_counts(counts)\n",
    "            super().__init__(X=counts, obs=metadata)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Either adata or both counts and metadata arguments must be provided.\"\n",
    "            )\n",
    "            \n",
    "         # Convert design_factors to list if a single string was provided.\n",
    "        self.design_factors = (\n",
    "            [design_factors] if isinstance(design_factors, str) else design_factors\n",
    "        )\n",
    "        self.continuous_factors = continuous_factors\n",
    "        \n",
    "        if self.obs[self.design_factors].isna().any().any():\n",
    "            raise ValueError(\"NaNs are not allowed in the design factors.\")\n",
    "        self.obs[self.design_factors] = self.obs[self.design_factors].astype(str)\n",
    "        \n",
    "        # Check that design factors don't contain underscores. If so, convert them to\n",
    "        # hyphens.\n",
    "        if np.any([\"_\" in factor for factor in self.design_factors]):\n",
    "            warnings.warn(\n",
    "                \"\"\"Same factor names in the design contain underscores ('_'). They will\n",
    "                be converted to hyphens ('-').\"\"\",\n",
    "                UserWarning,\n",
    "                stacklevel=2,\n",
    "            )\n",
    "\n",
    "            new_factors = replace_underscores(self.design_factors)\n",
    "\n",
    "            self.obs.rename(\n",
    "                columns={\n",
    "                    old_factor: new_factor\n",
    "                    for (old_factor, new_factor) in zip(self.design_factors, new_factors)\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "            self.design_factors = new_factors\n",
    "\n",
    "            # Also check continuous factors\n",
    "            if self.continuous_factors is not None:\n",
    "                self.continuous_factors = replace_underscores(self.continuous_factors)\n",
    "\n",
    "        # If ref_level has underscores, covert them to hyphens\n",
    "        # Don't raise a warning: it will be raised by build_design_matrix()\n",
    "        if ref_level is not None:\n",
    "            ref_level = replace_underscores(ref_level)\n",
    "        \n",
    "        # Build the design matrix\n",
    "        # Stored in the obsm attribute of the dataset\n",
    "        self.obsm[\"design_matrix\"] = build_design_matrix(\n",
    "            metadata=self.obs,\n",
    "            design_factors=self.design_factors,\n",
    "            continuous_factors=self.continuous_factors,\n",
    "            ref_level=ref_level,\n",
    "            expanded=False,\n",
    "            intercept=True,\n",
    "        )\n",
    "        \n",
    "        # Check that the design matrix has full rank\n",
    "        self._check_full_rank_design()\n",
    "        \n",
    "        self.min_mu = min_mu\n",
    "        self.min_disp = min_disp\n",
    "        self.max_disp = np.maximum(max_disp, self.n_obs)\n",
    "        self.refit_cooks = refit_cooks\n",
    "        self.ref_level = ref_level\n",
    "        self.min_replicates = min_replicates\n",
    "        self.beta_tol = beta_tol\n",
    "        self.n_processes = get_num_processes(n_cpus)\n",
    "        self.batch_size = batch_size\n",
    "        self.joblib_verbosity = joblib_verbosity\n",
    "        self.quiet = quiet\n",
    "    \n",
    "    def vst(\n",
    "        self,\n",
    "        use_design: bool = False,\n",
    "        fit_type: Literal[\"parametric\", \"mean\"] = \"parametric\",\n",
    "    ) -> None:\n",
    "        # Start by fitting median-of-ratio size factors, if not already present.\n",
    "        if \"size_factors\" not in self.obsm:\n",
    "            self.fit_size_factors()\n",
    "\n",
    "        if use_design:\n",
    "            # Check that the dispersion trend curve was fitted. If not, fit it.\n",
    "            # This will call previous functions in a cascade.\n",
    "            if \"trend_coeffs\" not in self.uns:\n",
    "                self.fit_dispersion_trend()\n",
    "        else:\n",
    "            # Reduce the design matrix to an intercept and reconstruct at the end\n",
    "            self.obsm[\"design_matrix_buffer\"] = self.obsm[\"design_matrix\"].copy()\n",
    "            self.obsm[\"design_matrix\"] = pd.DataFrame(\n",
    "                1, index=self.obs_names, columns=[[\"intercept\"]]\n",
    "            )\n",
    "            # Fit the trend curve with an intercept design\n",
    "            self.fit_genewise_dispersions()\n",
    "            if fit_type == \"parametric\":\n",
    "                self.fit_dispersion_trend()\n",
    "\n",
    "            # Restore the design matrix and free buffer\n",
    "            self.obsm[\"design_matrix\"] = self.obsm[\"design_matrix_buffer\"].copy()\n",
    "            del self.obsm[\"design_matrix_buffer\"]\n",
    "\n",
    "        # Apply VST\n",
    "        if fit_type == \"parametric\":\n",
    "            a0, a1 = self.uns[\"trend_coeffs\"]\n",
    "            cts = self.layers[\"normed_counts\"]\n",
    "            self.layers[\"vst_counts\"] = np.log2(\n",
    "                (1 + a1 + 2 * a0 * cts + 2 * np.sqrt(a0 * cts * (1 + a1 + a0 * cts)))\n",
    "                / (4 * a0)\n",
    "            )\n",
    "        elif fit_type == \"mean\":\n",
    "            gene_dispersions = self.varm[\"genewise_dispersions\"]\n",
    "            use_for_mean = gene_dispersions > 10 * self.min_disp\n",
    "            mean_disp = trim_mean(gene_dispersions[use_for_mean], proportiontocut=0.001)\n",
    "            self.layers[\"vst_counts\"] = (\n",
    "                2 * np.arcsinh(np.sqrt(mean_disp * self.layers[\"normed_counts\"]))\n",
    "                - np.log(mean_disp)\n",
    "                - np.log(4)\n",
    "            ) / np.log(2)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                f\"Found fit_type '{fit_type}'. Expected 'parametric' or 'mean'.\"\n",
    "            )\n",
    "            \n",
    "    def deseq2(self) -> None:\n",
    "        \n",
    "        \"\"\"Perform dispersion and log fold-change (LFC) estimation.\n",
    "\n",
    "        \"\"\"\n",
    "        # Compute DESeq2 normalization factors using the Median-of-ratios method\n",
    "        self.fit_size_factors()\n",
    "        # Fit an independent negative binomial model per gene\n",
    "        self.fit_genewise_dispersions()\n",
    "        # Fit a parameterized trend curve for dispersions, of the form\n",
    "        self.fit_dispersion_trend()\n",
    "        # Compute prior dispersion variance\n",
    "        self.fit_dispersion_prior()\n",
    "        # Refit genewise dispersions a posteriori (shrinks estimates towards trend curve)\n",
    "        self.fit_MAP_dispersions()\n",
    "        # Fit log-fold changes (in natural log scale)\n",
    "        self.fit_LFC()\n",
    "        self.calculate_cooks()\n",
    "        \n",
    "        if self.refit_cooks:\n",
    "            # Replace outlier counts, and refit dispersions and LFCs\n",
    "            # for genes that had outliers replaced\n",
    "            self.refit()\n",
    "        \n",
    "    def fit_size_factors(\n",
    "        self, fit_type: Literal[\"ratio\", \"iterative\"] = \"ratio\"\n",
    "    ) -> None:\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting size factors...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        if fit_type == \"iterative\":\n",
    "            self._fit_iterate_size_factors()\n",
    "        # Test whether it is possible to use median-of-ratios.\n",
    "        elif (self.X == 0).any(0).all():\n",
    "            # There is at least a zero for each gene\n",
    "            warnings.warn(\n",
    "                \"Every gene contains at least one zero, \"\n",
    "                \"cannot compute log geometric means. Switching to iterative mode.\",\n",
    "                RuntimeWarning,\n",
    "                stacklevel=2,\n",
    "            )\n",
    "            self._fit_iterate_size_factors()\n",
    "        else:\n",
    "            self.layers[\"normed_counts\"], self.obsm[\"size_factors\"] = deseq2_norm(self.X)\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "            \n",
    "    \n",
    "    def fit_genewise_dispersions(self) -> None:\n",
    "        \"\"\"Fit gene-wise dispersion estimates.\n",
    "\n",
    "        Fits a negative binomial per gene, independently.\n",
    "        \"\"\"\n",
    "        # Check that size factors are available. If not, compute them.\n",
    "        if \"size_factors\" not in self.obsm:\n",
    "            self.fit_size_factors()\n",
    "\n",
    "        # Exclude genes with all zeroes\n",
    "        self.varm[\"non_zero\"] = ~(self.X == 0).all(axis=0)\n",
    "        self.non_zero_idx = np.arange(self.n_vars)[self.varm[\"non_zero\"]]\n",
    "        self.non_zero_genes = self.var_names[self.varm[\"non_zero\"]]\n",
    "\n",
    "        if isinstance(self.non_zero_genes, pd.MultiIndex):\n",
    "            raise ValueError(\"non_zero_genes should not be a MultiIndex\")\n",
    "\n",
    "        # Fit \"method of moments\" dispersion estimates\n",
    "        self._fit_MoM_dispersions()\n",
    "\n",
    "        # Convert design_matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "        \n",
    "        if (\n",
    "            len(self.obsm[\"design_matrix\"].value_counts())\n",
    "            == self.obsm[\"design_matrix\"].shape[-1]\n",
    "        ):\n",
    "            with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "                mu_hat_ = np.array(\n",
    "                    Parallel(\n",
    "                        n_jobs=self.n_processes,\n",
    "                        verbose=self.joblib_verbosity,\n",
    "                        batch_size=self.batch_size,\n",
    "                    )(\n",
    "                        delayed(fit_lin_mu)(\n",
    "                            counts=self.X[:, i],\n",
    "                            size_factors=self.obsm[\"size_factors\"],\n",
    "                            design_matrix=design_matrix,\n",
    "                            min_mu=self.min_mu,\n",
    "                        )\n",
    "                        for i in self.non_zero_idx\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "                res = Parallel(\n",
    "                    n_jobs=self.n_processes,\n",
    "                    verbose=self.joblib_verbosity,\n",
    "                    batch_size=self.batch_size,\n",
    "                )(\n",
    "                    delayed(irls_solver)(\n",
    "                        counts=self.X[:, i],\n",
    "                        size_factors=self.obsm[\"size_factors\"],\n",
    "                        design_matrix=design_matrix,\n",
    "                        disp=self.varm[\"_MoM_dispersions\"][i],\n",
    "                        min_mu=self.min_mu,\n",
    "                        beta_tol=self.beta_tol,\n",
    "                    )\n",
    "                    for i in self.non_zero_idx\n",
    "                )\n",
    "\n",
    "                _, mu_hat_, _, _ = zip(*res)\n",
    "                mu_hat_ = np.array(mu_hat_)\n",
    "\n",
    "        self.layers[\"_mu_hat\"] = np.full((self.n_obs, self.n_vars), np.NaN)\n",
    "        self.layers[\"_mu_hat\"][:, self.varm[\"non_zero\"]] = mu_hat_.T\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting dispersions...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "            res = Parallel(\n",
    "                n_jobs=self.n_processes,\n",
    "                verbose=self.joblib_verbosity,\n",
    "                batch_size=self.batch_size,\n",
    "            )(\n",
    "                delayed(fit_alpha_mle)(\n",
    "                    counts=self.X[:, i],\n",
    "                    design_matrix=design_matrix,\n",
    "                    mu=self.layers[\"_mu_hat\"][:, i],\n",
    "                    alpha_hat=self.varm[\"_MoM_dispersions\"][i],\n",
    "                    min_disp=self.min_disp,\n",
    "                    max_disp=self.max_disp,\n",
    "                )\n",
    "                # for i in range(num_genes)\n",
    "                for i in self.non_zero_idx\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        dispersions_, l_bfgs_b_converged_ = zip(*res)\n",
    "\n",
    "        self.varm[\"genewise_dispersions\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"genewise_dispersions\"][self.varm[\"non_zero\"]] = np.clip(\n",
    "            dispersions_, self.min_disp, self.max_disp\n",
    "        )\n",
    "\n",
    "        self.varm[\"_genewise_converged\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"_genewise_converged\"][self.varm[\"non_zero\"]] = l_bfgs_b_converged_\n",
    "        \n",
    "    \n",
    "    def fit_dispersion_trend(self) -> None:\n",
    "        r\"\"\"Fit the dispersion trend coefficients.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that genewise dispersions are available. If not, compute them.\n",
    "        if \"genewise_dispersions\" not in self.varm:\n",
    "            self.fit_genewise_dispersions()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting dispersion trend curve...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        self.varm[\"_normed_means\"] = self.layers[\"normed_counts\"].mean(0)\n",
    "\n",
    "        # Exclude all-zero counts\n",
    "        targets = pd.Series(\n",
    "            self[:, self.non_zero_genes].varm[\"genewise_dispersions\"].copy(),\n",
    "            index=self.non_zero_genes,\n",
    "        )\n",
    "        covariates = sm.add_constant(\n",
    "            pd.Series(\n",
    "                1 / self[:, self.non_zero_genes].varm[\"_normed_means\"],\n",
    "                index=self.non_zero_genes,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for gene in self.non_zero_genes:\n",
    "            if (\n",
    "                np.isinf(covariates.loc[gene]).any()\n",
    "                or np.isnan(covariates.loc[gene]).any()\n",
    "            ):\n",
    "                targets.drop(labels=[gene], inplace=True)\n",
    "                covariates.drop(labels=[gene], inplace=True)\n",
    "\n",
    "        # Initialize coefficients\n",
    "        old_coeffs = pd.Series([0.1, 0.1])\n",
    "        coeffs = pd.Series([1.0, 1.0])\n",
    "\n",
    "        while (np.log(np.abs(coeffs / old_coeffs)) ** 2).sum() >= 1e-6:\n",
    "            glm_gamma = sm.GLM(\n",
    "                targets.values,\n",
    "                covariates.values,\n",
    "                family=sm.families.Gamma(link=sm.families.links.identity()),\n",
    "            )\n",
    "\n",
    "            res = glm_gamma.fit()\n",
    "            old_coeffs = coeffs.copy()\n",
    "            coeffs = res.params\n",
    "\n",
    "            # Filter out genes that are too far away from the curve before refitting\n",
    "            predictions = covariates.values @ coeffs\n",
    "            pred_ratios = (\n",
    "                self[:, covariates.index].varm[\"genewise_dispersions\"] / predictions\n",
    "            )\n",
    "\n",
    "            targets.drop(\n",
    "                targets[(pred_ratios < 1e-4) | (pred_ratios >= 15)].index,\n",
    "                inplace=True,\n",
    "            )\n",
    "            covariates.drop(\n",
    "                covariates[(pred_ratios < 1e-4) | (pred_ratios >= 15)].index,\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        self.uns[\"trend_coeffs\"] = pd.Series(coeffs, index=[\"a0\", \"a1\"])\n",
    "\n",
    "        self.varm[\"fitted_dispersions\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"fitted_dispersions\"][self.varm[\"non_zero\"]] = dispersion_trend(\n",
    "            self.varm[\"_normed_means\"][self.varm[\"non_zero\"]],\n",
    "            self.uns[\"trend_coeffs\"],\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def fit_dispersion_prior(self) -> None:\n",
    "        \"\"\"Fit dispersion variance priors and standard deviation of log-residuals.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that the dispersion trend curve was fitted. If not, fit it.\n",
    "        if \"fitted_dispersions\" not in self.varm:\n",
    "            self.fit_dispersion_trend()\n",
    "\n",
    "        # Exclude genes with all zeroes\n",
    "        num_samples = self.n_obs\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[-1]\n",
    "\n",
    "        # Check the degrees of freedom\n",
    "        if (num_samples - num_vars) <= 3:\n",
    "            warnings.warn(\n",
    "                \"As the residual degrees of freedom is less than 3, the distribution \"\n",
    "                \"of log dispersions is especially asymmetric and likely to be poorly \"\n",
    "                \"estimated by the MAD.\",\n",
    "                UserWarning,\n",
    "                stacklevel=2,\n",
    "            )\n",
    "\n",
    "        # Fit dispersions to the curve, and compute log residuals\n",
    "        disp_residuals = np.log(\n",
    "            self[:, self.non_zero_genes].varm[\"genewise_dispersions\"]\n",
    "        ) - np.log(self[:, self.non_zero_genes].varm[\"fitted_dispersions\"])\n",
    "\n",
    "        # Compute squared log-residuals and prior variance based on genes whose\n",
    "        # dispersions are above 100 * min_disp. This is to reproduce DESeq2's behaviour.\n",
    "        above_min_disp = self[:, self.non_zero_genes].varm[\"genewise_dispersions\"] >= (\n",
    "            100 * self.min_disp\n",
    "        )\n",
    "\n",
    "        self.uns[\"_squared_logres\"] = (\n",
    "            mean_absolute_deviation(disp_residuals[above_min_disp]) ** 2\n",
    "        )\n",
    "\n",
    "        self.uns[\"prior_disp_var\"] = np.maximum(\n",
    "            self.uns[\"_squared_logres\"] - polygamma(1, (num_samples - num_vars) / 2),\n",
    "            0.25,\n",
    "        )\n",
    "        \n",
    "    def fit_MAP_dispersions(self) -> None:\n",
    "        \"\"\"Fit Maximum a Posteriori dispersion estimates.\n",
    "\n",
    "        After MAP dispersions are fit, filter genes for which we don't apply shrinkage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that the dispersion prior variance is available. If not, compute it.\n",
    "        if \"prior_disp_var\" not in self.uns:\n",
    "            self.fit_dispersion_prior()\n",
    "\n",
    "        # Convert design matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting MAP dispersions...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "            res = Parallel(\n",
    "                n_jobs=self.n_processes,\n",
    "                verbose=self.joblib_verbosity,\n",
    "                batch_size=self.batch_size,\n",
    "            )(\n",
    "                delayed(fit_alpha_mle)(\n",
    "                    counts=self.X[:, i],\n",
    "                    design_matrix=design_matrix,\n",
    "                    mu=self.layers[\"_mu_hat\"][:, i],\n",
    "                    alpha_hat=self.varm[\"fitted_dispersions\"][i],\n",
    "                    min_disp=self.min_disp,\n",
    "                    max_disp=self.max_disp,\n",
    "                    prior_disp_var=self.uns[\"prior_disp_var\"].item(),\n",
    "                    cr_reg=True,\n",
    "                    prior_reg=True,\n",
    "                )\n",
    "                for i in self.non_zero_idx\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end-start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        dispersions_, l_bfgs_b_converged_ = zip(*res)\n",
    "\n",
    "        self.varm[\"MAP_dispersions\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"MAP_dispersions\"][self.varm[\"non_zero\"]] = np.clip(\n",
    "            dispersions_, self.min_disp, self.max_disp\n",
    "        )\n",
    "\n",
    "        self.varm[\"_MAP_converged\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"_MAP_converged\"][self.varm[\"non_zero\"]] = l_bfgs_b_converged_\n",
    "\n",
    "        # Filter outlier genes for which we won't apply shrinkage\n",
    "        self.varm[\"dispersions\"] = self.varm[\"MAP_dispersions\"].copy()\n",
    "        self.varm[\"_outlier_genes\"] = np.log(self.varm[\"genewise_dispersions\"]) > np.log(\n",
    "            self.varm[\"fitted_dispersions\"]\n",
    "        ) + 2 * np.sqrt(self.uns[\"_squared_logres\"])\n",
    "        self.varm[\"dispersions\"][self.varm[\"_outlier_genes\"]] = self.varm[\n",
    "            \"genewise_dispersions\"\n",
    "        ][self.varm[\"_outlier_genes\"]]\n",
    "        \n",
    "    def fit_LFC(self) -> None:\n",
    "        \"\"\"Fit log fold change (LFC) coefficients.\n",
    "\n",
    "        In the 2-level setting, the intercept corresponds to the base mean,\n",
    "        while the second is the actual LFC coefficient, in natural log scale.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that MAP dispersions are available. If not, compute them.\n",
    "        if \"dispersions\" not in self.varm:\n",
    "            self.fit_MAP_dispersions()\n",
    "\n",
    "        # Convert design matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting LFCs...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "            res = Parallel(\n",
    "                n_jobs=self.n_processes,\n",
    "                verbose=self.joblib_verbosity,\n",
    "                batch_size=self.batch_size,\n",
    "            )(\n",
    "                delayed(irls_solver)(\n",
    "                    counts=self.X[:, i],\n",
    "                    size_factors=self.obsm[\"size_factors\"],\n",
    "                    design_matrix=design_matrix,\n",
    "                    disp=self.varm[\"dispersions\"][i],\n",
    "                    min_mu=self.min_mu,\n",
    "                    beta_tol=self.beta_tol,\n",
    "                )\n",
    "                for i in self.non_zero_idx\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end-start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        MLE_lfcs_, mu_, hat_diagonals_, converged_ = zip(*res)\n",
    "        mu_ = np.array(mu_).T\n",
    "        hat_diagonals_ = np.array(hat_diagonals_).T\n",
    "\n",
    "        self.varm[\"LFC\"] = pd.DataFrame(\n",
    "            np.NaN,\n",
    "            index=self.var_names,\n",
    "            columns=self.obsm[\"design_matrix\"].columns,\n",
    "        )\n",
    "\n",
    "        self.varm[\"LFC\"].update(\n",
    "            pd.DataFrame(\n",
    "                MLE_lfcs_,\n",
    "                index=self.non_zero_genes,\n",
    "                columns=self.obsm[\"design_matrix\"].columns,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.layers[\"_mu_LFC\"] = np.full((self.n_obs, self.n_vars), np.NaN)\n",
    "        self.layers[\"_mu_LFC\"][:, self.varm[\"non_zero\"]] = mu_\n",
    "\n",
    "        self.layers[\"_hat_diagonals\"] = np.full((self.n_obs, self.n_vars), np.NaN)\n",
    "        self.layers[\"_hat_diagonals\"][:, self.varm[\"non_zero\"]] = hat_diagonals_\n",
    "\n",
    "        self.varm[\"_LFC_converged\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"_LFC_converged\"][self.varm[\"non_zero\"]] = converged_\n",
    "        \n",
    "    \n",
    "    def calculate_cooks(self) -> None:\n",
    "        if \"dispersions\" not in self.varm:\n",
    "            self.fit_MAP_dispersions()\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[-1]\n",
    "\n",
    "        # Keep only non-zero genes\n",
    "        nonzero_data = self[:, self.non_zero_genes]\n",
    "        normed_counts = pd.DataFrame(\n",
    "            nonzero_data.X / self.obsm[\"size_factors\"][:, None],\n",
    "            index=self.obs_names,\n",
    "            columns=self.non_zero_genes,\n",
    "        )\n",
    "        \n",
    "        dispersions = robust_method_of_moments_disp(\n",
    "            normed_counts, self.obsm[\"design_matrix\"]\n",
    "        )\n",
    "        V = (\n",
    "            nonzero_data.layers[\"_mu_LFC\"]\n",
    "            + dispersions.values[None, :] * nonzero_data.layers[\"_mu_LFC\"] ** 2\n",
    "        )\n",
    "        squared_pearson_res = (nonzero_data.X - nonzero_data.layers[\"_mu_LFC\"]) ** 2 / V\n",
    "        diag_mul = (\n",
    "            nonzero_data.layers[\"_hat_diagonals\"]\n",
    "            / (1 - nonzero_data.layers[\"_hat_diagonals\"]) ** 2\n",
    "        )\n",
    "\n",
    "        self.layers[\"cooks\"] = np.full((self.n_obs, self.n_vars), np.NaN)\n",
    "        self.layers[\"cooks\"][:, self.varm[\"non_zero\"]] = (\n",
    "            squared_pearson_res / num_vars * diag_mul\n",
    "        )\n",
    "        \n",
    "    def refit(self) -> None:\n",
    "        # Replace outlier counts\n",
    "        self._replace_outliers()\n",
    "        if not self.quiet:\n",
    "            print(\n",
    "                f\"Refitting {sum(self.varm['replaced']) } outliers.\\n\", file=sys.stderr\n",
    "            )\n",
    "\n",
    "        if sum(self.varm[\"replaced\"]) > 0:\n",
    "            # Refit dispersions and LFCs for genes that had outliers replaced\n",
    "            self._refit_without_outliers()\n",
    "            \n",
    "    \n",
    "    def _fit_MoM_dispersions(self) -> None:\n",
    "        # Check that size_factors are available. If not, compute them.\n",
    "        if \"normed_counts\" not in self.layers:\n",
    "            self.fit_size_factors()\n",
    "\n",
    "        rde = fit_rough_dispersions(\n",
    "            self.layers[\"normed_counts\"],\n",
    "            self.obsm[\"design_matrix\"],\n",
    "        )\n",
    "        mde = fit_moments_dispersions(\n",
    "            self.layers[\"normed_counts\"], self.obsm[\"size_factors\"]\n",
    "        )\n",
    "        alpha_hat = np.minimum(rde, mde)\n",
    "\n",
    "        self.varm[\"_MoM_dispersions\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"_MoM_dispersions\"][self.varm[\"non_zero\"]] = np.clip(\n",
    "            alpha_hat, self.min_disp, self.max_disp\n",
    "        )\n",
    "        \n",
    "\n",
    "    def plot_dispersions(\n",
    "        self, log: bool = True, save_path: Optional[str] = None, **kwargs\n",
    "    ) -> None:\n",
    "        disps = [\n",
    "            self.varm[\"genewise_dispersions\"],\n",
    "            self.varm[\"dispersions\"],\n",
    "            self.varm[\"fitted_dispersions\"],\n",
    "        ]\n",
    "        legend_labels = [\"Estimated\", \"Final\", \"Fitted\"]\n",
    "        make_scatter(\n",
    "            disps,\n",
    "            legend_labels=legend_labels,\n",
    "            x_val=self.varm[\"_normed_means\"],\n",
    "            log=log,\n",
    "            save_path=save_path,\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "    def _replace_outliers(self) -> None:\n",
    "        # Check that cooks distances are available. If not, compute them.\n",
    "        if \"cooks\" not in self.layers:\n",
    "            self.calculate_cooks()\n",
    "        \n",
    "        num_samples = self.n_obs\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[1]\n",
    "        # Check whether cohorts have enough samples to allow refitting\n",
    "        n_or_more = (\n",
    "            self.obsm[\"design_matrix\"][\n",
    "                self.obsm[\"design_matrix\"].columns[-1]\n",
    "            ].value_counts()\n",
    "            >= self.min_replicates\n",
    "        )\n",
    "        if n_or_more.sum() == 0:\n",
    "            # No sample can be replaced. Set self.replaced to False and exit.\n",
    "            self.varm[\"replaced\"] = pd.Series(False, index=self.var_names)\n",
    "            return\n",
    "\n",
    "        replaceable = n_or_more[\n",
    "            self.obsm[\"design_matrix\"][self.obsm[\"design_matrix\"].columns[-1]]\n",
    "        ]\n",
    "\n",
    "        self.obsm[\"replaceable\"] = replaceable.values\n",
    "\n",
    "        # Get positions of counts with cooks above threshold\n",
    "        cooks_cutoff = f.ppf(0.99, num_vars, num_samples - num_vars)\n",
    "        idx = self.layers[\"cooks\"] > cooks_cutoff\n",
    "        self.varm[\"replaced\"] = idx.any(axis=0)\n",
    "\n",
    "        if sum(self.varm[\"replaced\"] > 0):\n",
    "            # Compute replacement counts: trimmed means * size_factors\n",
    "            self.counts_to_refit = self[:, self.varm[\"replaced\"]].copy()\n",
    "\n",
    "            trim_base_mean = pd.DataFrame(\n",
    "                cast(\n",
    "                    np.ndarray,\n",
    "                    trimmed_mean(\n",
    "                        self.counts_to_refit.X / self.obsm[\"size_factors\"][:, None],\n",
    "                        trim=0.2,\n",
    "                        axis=0,\n",
    "                    ),\n",
    "                ),\n",
    "                index=self.counts_to_refit.var_names,\n",
    "            )\n",
    "\n",
    "            replacement_counts = (\n",
    "                pd.DataFrame(\n",
    "                    trim_base_mean.values * self.obsm[\"size_factors\"],\n",
    "                    index=self.counts_to_refit.var_names,\n",
    "                    columns=self.counts_to_refit.obs_names,\n",
    "                )\n",
    "                .astype(int)\n",
    "                .T\n",
    "            )\n",
    "\n",
    "            self.counts_to_refit.X[\n",
    "                self.obsm[\"replaceable\"][:, None] & idx[:, self.varm[\"replaced\"]]\n",
    "            ] = replacement_counts.values[\n",
    "                self.obsm[\"replaceable\"][:, None] & idx[:, self.varm[\"replaced\"]]\n",
    "            ]\n",
    "\n",
    "\n",
    "      \n",
    "    def _refit_without_outliers(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        \"\"\"Re-run the whole DESeq2 pipeline with replaced outliers.\"\"\"\n",
    "        assert (\n",
    "            self.refit_cooks\n",
    "        ), \"Trying to refit Cooks outliers but the 'refit_cooks' flag is set to False\"\n",
    "\n",
    "        # Check that _replace_outliers() was previously run.\n",
    "        if \"replaced\" not in self.varm:\n",
    "            self._replace_outliers()\n",
    "\n",
    "        # Only refit genes for which replacing outliers hasn't resulted in all zeroes\n",
    "        new_all_zeroes = (self.counts_to_refit.X == 0).all(axis=0)\n",
    "        self.new_all_zeroes_genes = self.counts_to_refit.var_names[new_all_zeroes]\n",
    "        if (~new_all_zeroes).sum() == 0:  # if no gene can be refit, we can skip\n",
    "            return\n",
    "\n",
    "        self.counts_to_refit = self.counts_to_refit[:, ~new_all_zeroes].copy()\n",
    "        if isinstance(self.new_all_zeroes_genes, pd.MultiIndex):\n",
    "            raise ValueError\n",
    "\n",
    "        sub_dds = DeseqDataSet(\n",
    "            counts=pd.DataFrame(\n",
    "                self.counts_to_refit.X,\n",
    "                index=self.counts_to_refit.obs_names,\n",
    "                columns=self.counts_to_refit.var_names,\n",
    "            ),\n",
    "            metadata=self.obs,\n",
    "            design_factors=self.design_factors,\n",
    "            ref_level=self.ref_level,\n",
    "            min_mu=self.min_mu,\n",
    "            min_disp=self.min_disp,\n",
    "            max_disp=self.max_disp,\n",
    "            refit_cooks=self.refit_cooks,\n",
    "            min_replicates=self.min_replicates,\n",
    "            beta_tol=self.beta_tol,\n",
    "            n_cpus=self.n_processes,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "        # Use the same size factors\n",
    "        sub_dds.obsm[\"size_factors\"] = self.counts_to_refit.obsm[\"size_factors\"]\n",
    "\n",
    "        # Estimate gene-wise dispersions.\n",
    "        sub_dds.fit_genewise_dispersions()\n",
    "\n",
    "        # Compute trend dispersions.\n",
    "        # Note: the trend curve is not refitted.\n",
    "        sub_dds.uns[\"trend_coeffs\"] = self.uns[\"trend_coeffs\"]\n",
    "        sub_dds.varm[\"_normed_means\"] = (\n",
    "            self.counts_to_refit.X / self.counts_to_refit.obsm[\"size_factors\"][:, None]\n",
    "        ).mean(0)\n",
    "        sub_dds.varm[\"fitted_dispersions\"] = dispersion_trend(\n",
    "            sub_dds.varm[\"_normed_means\"],\n",
    "            sub_dds.uns[\"trend_coeffs\"],\n",
    "        )\n",
    "\n",
    "        # Estimate MAP dispersions.\n",
    "        # Note: the prior variance is not recomputed.\n",
    "        sub_dds.uns[\"_squared_logres\"] = self.uns[\"_squared_logres\"]\n",
    "        sub_dds.uns[\"prior_disp_var\"] = self.uns[\"prior_disp_var\"]\n",
    "\n",
    "        sub_dds.fit_MAP_dispersions()\n",
    "\n",
    "        # Estimate log-fold changes (in natural log scale)\n",
    "        sub_dds.fit_LFC()\n",
    "\n",
    "        # Replace values in main object\n",
    "        to_replace = self.varm[\"replaced\"].copy()\n",
    "        # Only replace if genes are not all zeroes after outlier replacement\n",
    "        to_replace[to_replace] = ~new_all_zeroes\n",
    "\n",
    "        self.varm[\"_normed_means\"][to_replace] = sub_dds.varm[\"_normed_means\"]\n",
    "        self.varm[\"LFC\"][to_replace] = sub_dds.varm[\"LFC\"]\n",
    "        self.varm[\"dispersions\"][to_replace] = sub_dds.varm[\"dispersions\"]\n",
    "\n",
    "        replace_cooks = pd.DataFrame(self.layers[\"cooks\"].copy())\n",
    "        replace_cooks.loc[self.obsm[\"replaceable\"], to_replace] = 0.0\n",
    "\n",
    "        self.layers[\"replace_cooks\"] = replace_cooks\n",
    "        # Take into account new all-zero genes\n",
    "        if (new_all_zeroes).sum() > 0:\n",
    "            self[:, self.new_all_zeroes_genes].varm[\"_normed_means\"] = np.zeros(\n",
    "                new_all_zeroes.sum()\n",
    "            )\n",
    "            self[:, self.new_all_zeroes_genes].varm[\"LFC\"] = np.zeros(\n",
    "                new_all_zeroes.sum()\n",
    "            )\n",
    "    \n",
    "    def _fit_iterate_size_factors(self, niter: int = 10, quant: float = 0.95) -> None:\n",
    "        \"\"\"\n",
    "        Fit size factors using the ``iterative`` method.\n",
    "\n",
    "        Used when each gene has at least one zero.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        niter : int\n",
    "            Maximum number of iterations to perform (default: ``10``).\n",
    "\n",
    "        quant : float\n",
    "            Quantile value at which negative likelihood is cut in the optimization\n",
    "            (default: ``0.95``).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize size factors and normed counts fields\n",
    "        self.obsm[\"size_factors\"] = np.ones(self.n_obs)\n",
    "        self.layers[\"normed_counts\"] = self.X\n",
    "\n",
    "        # Reduce the design matrix to an intercept and reconstruct at the end\n",
    "        self.obsm[\"design_matrix_buffer\"] = self.obsm[\"design_matrix\"].copy()\n",
    "        self.obsm[\"design_matrix\"] = pd.DataFrame(\n",
    "            1, index=self.obs_names, columns=[[\"intercept\"]]\n",
    "        )\n",
    "\n",
    "        # Fit size factors using MLE\n",
    "        def objective(p):\n",
    "            sf = np.exp(p - np.mean(p))\n",
    "            nll = nb_nll(\n",
    "                counts=self[:, self.non_zero_genes].X,\n",
    "                mu=self[:, self.non_zero_genes].layers[\"_mu_hat\"]\n",
    "                / self.obsm[\"size_factors\"][:, None]\n",
    "                * sf[:, None],\n",
    "                alpha=self[:, self.non_zero_genes].varm[\"dispersions\"],\n",
    "            )\n",
    "            # Take out the lowest likelihoods (highest neg) from the sum\n",
    "            return np.sum(nll[nll < np.quantile(nll, quant)])\n",
    "\n",
    "        for i in range(niter):\n",
    "            # Estimate dispersions based on current size factors\n",
    "            self.fit_genewise_dispersions()\n",
    "\n",
    "            # Use a mean trend curve\n",
    "            use_for_mean_genes = self.var_names[\n",
    "                (self.varm[\"genewise_dispersions\"] > 10 * self.min_disp)\n",
    "                & self.varm[\"non_zero\"]\n",
    "            ]\n",
    "\n",
    "            mean_disp = trimmed_mean(\n",
    "                self[:, use_for_mean_genes].varm[\"genewise_dispersions\"], trim=0.001\n",
    "            )\n",
    "            self.varm[\"fitted_dispersions\"] = np.ones(self.n_vars) * mean_disp\n",
    "            self.fit_dispersion_prior()\n",
    "            self.fit_MAP_dispersions()\n",
    "            old_sf = self.obsm[\"size_factors\"].copy()\n",
    "\n",
    "            # Fit size factors using MLE\n",
    "            res = minimize(objective, np.log(old_sf), method=\"Powell\")\n",
    "\n",
    "            self.obsm[\"size_factors\"] = np.exp(res.x - np.mean(res.x))\n",
    "\n",
    "            if not res.success:\n",
    "                print(\"A size factor fitting iteration failed.\", file=sys.stderr)\n",
    "                break\n",
    "\n",
    "            if (i > 1) and np.sum(\n",
    "                (np.log(old_sf) - np.log(self.obsm[\"size_factors\"])) ** 2\n",
    "            ) < 1e-4:\n",
    "                break\n",
    "            elif i == niter - 1:\n",
    "                print(\"Iterative size factor fitting did not converge.\", file=sys.stderr)\n",
    "\n",
    "        # Restore the design matrix and free buffer\n",
    "        self.obsm[\"design_matrix\"] = self.obsm[\"design_matrix_buffer\"].copy()\n",
    "        del self.obsm[\"design_matrix_buffer\"]\n",
    "\n",
    "        # Store normalized counts\n",
    "        self.layers[\"normed_counts\"] = self.X / self.obsm[\"size_factors\"][:, None]\n",
    "        \n",
    "    def _check_full_rank_design(self):\n",
    "        \"\"\"Check that the design matrix has full column rank.\"\"\"\n",
    "        rank = np.linalg.matrix_rank(self.obsm[\"design_matrix\"])\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[1]\n",
    "\n",
    "        if rank < num_vars:\n",
    "            warnings.warn(\n",
    "                \"The design matrix is not full rank, so the model cannot be \"\n",
    "                \"fitted, but some operations like design-free VST remain possible. \"\n",
    "                \"To perform differential expression analysis, please remove the design \"\n",
    "                \"variables that are linear combinations of others.\",\n",
    "                UserWarning,\n",
    "                stacklevel=2,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d2c8f-f08c-403d-a579-ed51bb063f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fe542c7-b172-4456-9ea2-15c303427460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "rna_counts = pd.read_csv('data_simulation/sim4_omics/rna_cnv.csv', index_col=0)\n",
    "rna_counts = rna_counts.T\n",
    "metadata = pd.read_csv('data_simulation/sim4_omics/metadata.csv', index_col=0)\n",
    "#cnv_tumor = pd.read_csv('data_simulation/cnv_tumor.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02c4a626-3f0d-4fcf-913a-669929a75770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G 1</th>\n",
       "      <th>G 2</th>\n",
       "      <th>G 3</th>\n",
       "      <th>G 4</th>\n",
       "      <th>G 5</th>\n",
       "      <th>G 6</th>\n",
       "      <th>G 7</th>\n",
       "      <th>G 8</th>\n",
       "      <th>G 9</th>\n",
       "      <th>G 10</th>\n",
       "      <th>...</th>\n",
       "      <th>G 14991</th>\n",
       "      <th>G 14992</th>\n",
       "      <th>G 14993</th>\n",
       "      <th>G 14994</th>\n",
       "      <th>G 14995</th>\n",
       "      <th>G 14996</th>\n",
       "      <th>G 14997</th>\n",
       "      <th>G 14998</th>\n",
       "      <th>G 14999</th>\n",
       "      <th>G 15000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>179.000002</td>\n",
       "      <td>677.000007</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1428.000014</td>\n",
       "      <td>94.000001</td>\n",
       "      <td>115.000001</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2804.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>407.000004</td>\n",
       "      <td>1032.000005</td>\n",
       "      <td>1174.000012</td>\n",
       "      <td>221.000002</td>\n",
       "      <td>405.000004</td>\n",
       "      <td>349.000003</td>\n",
       "      <td>558.000006</td>\n",
       "      <td>7.0</td>\n",
       "      <td>229.500002</td>\n",
       "      <td>362.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>438.000002</td>\n",
       "      <td>846.000004</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3748.000019</td>\n",
       "      <td>178.000001</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>5246.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>452.000005</td>\n",
       "      <td>504.000005</td>\n",
       "      <td>1132.500008</td>\n",
       "      <td>249.000002</td>\n",
       "      <td>490.000005</td>\n",
       "      <td>772.000008</td>\n",
       "      <td>1333.500009</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111.000001</td>\n",
       "      <td>359.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>146.000001</td>\n",
       "      <td>611.000006</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2511.000025</td>\n",
       "      <td>737.000007</td>\n",
       "      <td>77.000001</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3103.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>1143.000008</td>\n",
       "      <td>737.000007</td>\n",
       "      <td>1189.000012</td>\n",
       "      <td>358.000004</td>\n",
       "      <td>314.000003</td>\n",
       "      <td>753.000008</td>\n",
       "      <td>1248.000008</td>\n",
       "      <td>14.0</td>\n",
       "      <td>247.000002</td>\n",
       "      <td>651.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>115.000001</td>\n",
       "      <td>488.000005</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2263.000023</td>\n",
       "      <td>165.000002</td>\n",
       "      <td>105.000001</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2428.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>902.000009</td>\n",
       "      <td>636.000006</td>\n",
       "      <td>705.000014</td>\n",
       "      <td>401.000004</td>\n",
       "      <td>613.000006</td>\n",
       "      <td>461.000005</td>\n",
       "      <td>809.000008</td>\n",
       "      <td>11.0</td>\n",
       "      <td>219.000002</td>\n",
       "      <td>486.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S5</th>\n",
       "      <td>116.000001</td>\n",
       "      <td>352.000002</td>\n",
       "      <td>1080.000005</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4292.000021</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>458.000002</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7088.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>713.000007</td>\n",
       "      <td>548.000005</td>\n",
       "      <td>2007.000013</td>\n",
       "      <td>774.000005</td>\n",
       "      <td>748.500005</td>\n",
       "      <td>789.000008</td>\n",
       "      <td>912.000009</td>\n",
       "      <td>11.0</td>\n",
       "      <td>466.000002</td>\n",
       "      <td>390.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S68</th>\n",
       "      <td>160.000002</td>\n",
       "      <td>1280.000013</td>\n",
       "      <td>4200.000042</td>\n",
       "      <td>128.000001</td>\n",
       "      <td>18688.000187</td>\n",
       "      <td>752.000008</td>\n",
       "      <td>776.000008</td>\n",
       "      <td>80.000001</td>\n",
       "      <td>208.000002</td>\n",
       "      <td>20496.000205</td>\n",
       "      <td>...</td>\n",
       "      <td>474.000005</td>\n",
       "      <td>596.000006</td>\n",
       "      <td>1027.000010</td>\n",
       "      <td>223.000002</td>\n",
       "      <td>1246.500012</td>\n",
       "      <td>677.000007</td>\n",
       "      <td>1309.000013</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.000002</td>\n",
       "      <td>447.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S69</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>256.500003</td>\n",
       "      <td>699.000007</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2944.500029</td>\n",
       "      <td>139.500001</td>\n",
       "      <td>81.000001</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>69.000001</td>\n",
       "      <td>4017.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>651.000007</td>\n",
       "      <td>758.000008</td>\n",
       "      <td>1186.500012</td>\n",
       "      <td>313.000003</td>\n",
       "      <td>1148.000011</td>\n",
       "      <td>321.000003</td>\n",
       "      <td>701.000007</td>\n",
       "      <td>9.0</td>\n",
       "      <td>291.000003</td>\n",
       "      <td>561.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S70</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>324.000003</td>\n",
       "      <td>514.500005</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>3411.000034</td>\n",
       "      <td>175.500002</td>\n",
       "      <td>153.000002</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>4837.500048</td>\n",
       "      <td>...</td>\n",
       "      <td>342.000003</td>\n",
       "      <td>814.000008</td>\n",
       "      <td>1066.000011</td>\n",
       "      <td>235.000002</td>\n",
       "      <td>766.000008</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>825.000008</td>\n",
       "      <td>6.0</td>\n",
       "      <td>184.000002</td>\n",
       "      <td>655.500007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S71</th>\n",
       "      <td>70.000001</td>\n",
       "      <td>124.000001</td>\n",
       "      <td>556.000006</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2732.000027</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2314.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>638.000006</td>\n",
       "      <td>944.000009</td>\n",
       "      <td>1119.000011</td>\n",
       "      <td>440.000004</td>\n",
       "      <td>750.000008</td>\n",
       "      <td>556.000006</td>\n",
       "      <td>654.000007</td>\n",
       "      <td>14.0</td>\n",
       "      <td>335.000003</td>\n",
       "      <td>435.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S72</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>153.000002</td>\n",
       "      <td>433.000004</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2478.000025</td>\n",
       "      <td>103.000001</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3155.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>834.000008</td>\n",
       "      <td>648.000006</td>\n",
       "      <td>590.000006</td>\n",
       "      <td>980.000010</td>\n",
       "      <td>459.000005</td>\n",
       "      <td>519.000005</td>\n",
       "      <td>1802.000018</td>\n",
       "      <td>10.0</td>\n",
       "      <td>227.000002</td>\n",
       "      <td>519.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  15000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            G 1          G 2          G 3         G 4           G 5  \\\n",
       "S1    45.000000   179.000002   677.000007   16.000000   1428.000014   \n",
       "S2    78.000000   438.000002   846.000004   30.000000   3748.000019   \n",
       "S3    18.000000   146.000001   611.000006    6.000000   2511.000025   \n",
       "S4     4.000000   115.000001   488.000005    9.000000   2263.000023   \n",
       "S5   116.000001   352.000002  1080.000005   54.000000   4292.000021   \n",
       "..          ...          ...          ...         ...           ...   \n",
       "S68  160.000002  1280.000013  4200.000042  128.000001  18688.000187   \n",
       "S69   24.000000   256.500003   699.000007    7.500000   2944.500029   \n",
       "S70   27.000000   324.000003   514.500005   10.500000   3411.000034   \n",
       "S71   70.000001   124.000001   556.000006   27.000000   2732.000027   \n",
       "S72   33.000000   153.000002   433.000004   22.000000   2478.000025   \n",
       "\n",
       "            G 6         G 7        G 8         G 9          G 10  ...  \\\n",
       "S1    94.000001  115.000001  13.000000   12.000000   2804.000028  ...   \n",
       "S2   178.000001   40.000000  22.000000   66.000000   5246.000026  ...   \n",
       "S3   737.000007   77.000001  28.000000   29.000000   3103.000031  ...   \n",
       "S4   165.000002  105.000001  24.000000   32.000000   2428.000024  ...   \n",
       "S5    96.000000  458.000002  70.000000   50.000000   7088.000035  ...   \n",
       "..          ...         ...        ...         ...           ...  ...   \n",
       "S68  752.000008  776.000008  80.000001  208.000002  20496.000205  ...   \n",
       "S69  139.500001   81.000001  15.000000   69.000001   4017.000040  ...   \n",
       "S70  175.500002  153.000002  30.000000   39.000000   4837.500048  ...   \n",
       "S71   10.000000   32.000000  24.000000   18.000000   2314.000023  ...   \n",
       "S72  103.000001   30.000000  28.000000   18.000000   3155.000032  ...   \n",
       "\n",
       "         G 14991      G 14992      G 14993     G 14994      G 14995  \\\n",
       "S1    407.000004  1032.000005  1174.000012  221.000002   405.000004   \n",
       "S2    452.000005   504.000005  1132.500008  249.000002   490.000005   \n",
       "S3   1143.000008   737.000007  1189.000012  358.000004   314.000003   \n",
       "S4    902.000009   636.000006   705.000014  401.000004   613.000006   \n",
       "S5    713.000007   548.000005  2007.000013  774.000005   748.500005   \n",
       "..           ...          ...          ...         ...          ...   \n",
       "S68   474.000005   596.000006  1027.000010  223.000002  1246.500012   \n",
       "S69   651.000007   758.000008  1186.500012  313.000003  1148.000011   \n",
       "S70   342.000003   814.000008  1066.000011  235.000002   766.000008   \n",
       "S71   638.000006   944.000009  1119.000011  440.000004   750.000008   \n",
       "S72   834.000008   648.000006   590.000006  980.000010   459.000005   \n",
       "\n",
       "        G 14996      G 14997  G 14998     G 14999     G 15000  \n",
       "S1   349.000003   558.000006      7.0  229.500002  362.000004  \n",
       "S2   772.000008  1333.500009      7.0  111.000001  359.000004  \n",
       "S3   753.000008  1248.000008     14.0  247.000002  651.000004  \n",
       "S4   461.000005   809.000008     11.0  219.000002  486.000005  \n",
       "S5   789.000008   912.000009     11.0  466.000002  390.000004  \n",
       "..          ...          ...      ...         ...         ...  \n",
       "S68  677.000007  1309.000013      2.0  212.000002  447.000004  \n",
       "S69  321.000003   701.000007      9.0  291.000003  561.000006  \n",
       "S70   40.000000   825.000008      6.0  184.000002  655.500007  \n",
       "S71  556.000006   654.000007     14.0  335.000003  435.000004  \n",
       "S72  519.000005  1802.000018     10.0  227.000002  519.000005  \n",
       "\n",
       "[72 rows x 15000 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e67307-620e-4778-a155-e682e688cd2b",
   "metadata": {},
   "source": [
    "#### Generate CN corrected RNA counts matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3a5b559b-33de-40fd-bb3b-9d1b850767cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_matrix(rows, cols, min_val, max_val):\n",
    "    return [[random.randint(min_val, max_val) for _ in range(cols)] for _ in range(rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "08f220b1-7108-46fb-aca0-67b40ff4d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rna_cnv_count_matrix(rna_counts, cnv_tumor):\n",
    "    cnv_normal_mat = create_matrix(19979, 45, 2, 2)\n",
    "    cnv_normal_mat= np.array(cnv_normal)\n",
    "    cnv_tumor_mat = np.array(cnv_tumor)\n",
    "    cnv = np.concatenate((cnv_tumor_mat, cnv_normal_mat), axis=1) \n",
    "    cnv = cnv/2\n",
    "\n",
    "    counts_mat = np.array(rna_counts)\n",
    "    rna_counts_cnv = np.multiply(counts_mat, cnv)\n",
    "    rna_counts_cnv = pd.DataFrame(rna_counts_cnv)\n",
    "    \n",
    "    # Reassign rownames and column names\n",
    "    gene_id = rna_counts.index\n",
    "    gene_id = pd.DataFrame(gene_id)\n",
    "    gene_id.rename(columns = {0:'geneID'}, inplace = True) \n",
    "    rna_counts_cnv = pd.concat([gene_id, rna_counts_cnv], axis=1)\n",
    "    rna_counts_cnv.set_index('geneID', inplace = True)\n",
    "    sample_id = rna_counts.columns\n",
    "    rna_counts_cnv.columns = sample_id\n",
    "    rna_counts_cnv = rna_counts_cnv.T\n",
    "\n",
    "    return rna_counts_cnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "97dfca70-4a39-470e-be9e-9c6c80f64ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_counts_cnv = rna_cnv_count_matrix(rna_counts, cnv_tumor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a755d3c-7428-45c3-a2c7-76e2f25a1528",
   "metadata": {},
   "source": [
    "#### Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5266efef-5d84-4377-a341-ac7ccf7aad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pydeseqCN(rna_counts, metadata):\n",
    "    \n",
    "    # Create dds object\n",
    "    dds = DeseqDataSet(\n",
    "        counts=rna_counts,\n",
    "        metadata=metadata,\n",
    "        design_factors=\"condition\",\n",
    "        refit_cooks=False,\n",
    "        n_cpus=8\n",
    "    )\n",
    "    dds.deseq2()\n",
    "    # Statistical test\n",
    "    stat_res = DeseqStats(dds, \n",
    "                      contrast=['condition', 'B', 'A'], \n",
    "                      alpha=0.05, \n",
    "                      cooks_filter=False, \n",
    "                      independent_filter=True, \n",
    "                      prior_LFC_var=None, \n",
    "                      lfc_null=0, \n",
    "                      alt_hypothesis=None, \n",
    "                      inference=None, quiet=False\n",
    "                         )\n",
    "    stat_res.summary()\n",
    "    # LFC shrinkage (apeGLM) \n",
    "    stat_res.lfc_shrink(coeff=\"condition_B_vs_A\")\n",
    "    res_df = stat_res.results_df\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9d38e62-c8b4-483e-b88b-6b3e9c212e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting size factors...\n",
      "... done in 0.04 seconds.\n",
      "\n",
      "Fitting dispersions...\n",
      "... done in 1.10 seconds.\n",
      "\n",
      "Fitting dispersion trend curve...\n",
      "... done in 0.74 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 1.31 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 0.56 seconds.\n",
      "\n",
      "Running Wald tests...\n",
      "... done in 0.42 seconds.\n",
      "\n",
      "Fitting MAP LFCs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2 fold change & Wald test p-value: condition B vs A\n",
      "            baseMean  log2FoldChange     lfcSE      stat    pvalue      padj\n",
      "G 1        47.724375       -0.146760  0.293935 -0.499296  0.617571  0.999868\n",
      "G 2       363.551597       -0.067415  0.211498 -0.318749  0.749917  0.999868\n",
      "G 3       879.641536       -0.087083  0.171480 -0.507833  0.611570  0.999868\n",
      "G 4        24.362647        0.233736  0.268687  0.869921  0.384343  0.999868\n",
      "G 5      3707.907244       -0.062938  0.192512 -0.326931  0.743720  0.999868\n",
      "...              ...             ...       ...       ...       ...       ...\n",
      "G 14996   594.658205       -0.197746  0.184121 -1.074002  0.282822  0.999868\n",
      "G 14997  1132.731293        0.076383  0.139005  0.549498  0.582664  0.999868\n",
      "G 14998    14.009224        0.401684  0.229216  1.752428  0.079700  0.999868\n",
      "G 14999   265.627439        0.098208  0.148001  0.663565  0.506969  0.999868\n",
      "G 15000   438.623532       -0.003224  0.089394 -0.036066  0.971230  0.999868\n",
      "\n",
      "[15000 rows x 6 columns]\n",
      "Shrunk log2 fold change & Wald test p-value: condition B vs A\n",
      "            baseMean  log2FoldChange     lfcSE      stat    pvalue      padj\n",
      "G 1        47.724375   -1.759724e-06  0.001408 -0.499296  0.617571  0.999868\n",
      "G 2       363.551597   -1.657652e-06  0.001426 -0.318749  0.749917  0.999868\n",
      "G 3       879.641536   -3.458112e-06  0.001421 -0.507833  0.611570  0.999868\n",
      "G 4        24.362647    3.328379e-06  0.001500  0.869921  0.384343  0.999868\n",
      "G 5      3707.907244   -1.724637e-06  0.001427 -0.326931  0.743720  0.999868\n",
      "...              ...             ...       ...       ...       ...       ...\n",
      "G 14996   594.658205   -6.047613e-06  0.001396 -1.074002  0.282822  0.999868\n",
      "G 14997  1132.731293    4.188237e-06  0.001462  0.549498  0.582664  0.999868\n",
      "G 14998    14.009224    7.927858e-06  0.001532  1.752428  0.079700  0.999868\n",
      "G 14999   265.627439    3.617875e-06  0.001467  0.663565  0.506969  0.999868\n",
      "G 15000   438.623532   -4.861576e-07  0.001441 -0.036066  0.971230  0.999868\n",
      "\n",
      "[15000 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... done in 2.19 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = test_pydeseqCN(rna_counts, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385ed3e-6706-4beb-9ee1-95c5d4fb7471",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6282e460-42b5-4633-b2fc-a82e2dc9ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the path to directory where you would like results to be saved\n",
    "OUTPUT_PATH = \"data_simulation/results/sim_4/\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)  # Create path if it doesn't exist\n",
    "res.to_csv(os.path.join(OUTPUT_PATH, \"res_sim_cnv.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7480b3cf-c5f3-42bd-b07e-2a9abf9a160b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseMean</th>\n",
       "      <th>log2FoldChange</th>\n",
       "      <th>lfcSE</th>\n",
       "      <th>stat</th>\n",
       "      <th>pvalue</th>\n",
       "      <th>padj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G 1</th>\n",
       "      <td>47.724375</td>\n",
       "      <td>-1.759724e-06</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>-0.499296</td>\n",
       "      <td>0.617571</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 2</th>\n",
       "      <td>363.551597</td>\n",
       "      <td>-1.657652e-06</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>-0.318749</td>\n",
       "      <td>0.749917</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 3</th>\n",
       "      <td>879.641536</td>\n",
       "      <td>-3.458112e-06</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>-0.507833</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 4</th>\n",
       "      <td>24.362647</td>\n",
       "      <td>3.328379e-06</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.869921</td>\n",
       "      <td>0.384343</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 5</th>\n",
       "      <td>3707.907244</td>\n",
       "      <td>-1.724637e-06</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>-0.326931</td>\n",
       "      <td>0.743720</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 14996</th>\n",
       "      <td>594.658205</td>\n",
       "      <td>-6.047613e-06</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>-1.074002</td>\n",
       "      <td>0.282822</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 14997</th>\n",
       "      <td>1132.731293</td>\n",
       "      <td>4.188237e-06</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.549498</td>\n",
       "      <td>0.582664</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 14998</th>\n",
       "      <td>14.009224</td>\n",
       "      <td>7.927858e-06</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>1.752428</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 14999</th>\n",
       "      <td>265.627439</td>\n",
       "      <td>3.617875e-06</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.663565</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G 15000</th>\n",
       "      <td>438.623532</td>\n",
       "      <td>-4.861576e-07</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>-0.036066</td>\n",
       "      <td>0.971230</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            baseMean  log2FoldChange     lfcSE      stat    pvalue      padj\n",
       "G 1        47.724375   -1.759724e-06  0.001408 -0.499296  0.617571  0.999868\n",
       "G 2       363.551597   -1.657652e-06  0.001426 -0.318749  0.749917  0.999868\n",
       "G 3       879.641536   -3.458112e-06  0.001421 -0.507833  0.611570  0.999868\n",
       "G 4        24.362647    3.328379e-06  0.001500  0.869921  0.384343  0.999868\n",
       "G 5      3707.907244   -1.724637e-06  0.001427 -0.326931  0.743720  0.999868\n",
       "...              ...             ...       ...       ...       ...       ...\n",
       "G 14996   594.658205   -6.047613e-06  0.001396 -1.074002  0.282822  0.999868\n",
       "G 14997  1132.731293    4.188237e-06  0.001462  0.549498  0.582664  0.999868\n",
       "G 14998    14.009224    7.927858e-06  0.001532  1.752428  0.079700  0.999868\n",
       "G 14999   265.627439    3.617875e-06  0.001467  0.663565  0.506969  0.999868\n",
       "G 15000   438.623532   -4.861576e-07  0.001441 -0.036066  0.971230  0.999868\n",
       "\n",
       "[15000 rows x 6 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "488a647e-7e6f-4d57-89cb-b80745302117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee359b19-ce89-4762-8d7f-a9a418ba3057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
